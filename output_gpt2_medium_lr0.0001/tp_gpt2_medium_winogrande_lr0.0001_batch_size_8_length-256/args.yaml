batch_size: 8
dataset: winogrande
eval_steps: 100
learning_rate: 3.0e-05
local_rank: 0
loss_rate: 0.0001
max_length: 256
max_samples: 0
max_steps: 100000
model_name: gpt2-medium
output_dir: output_gpt2_medium_lr0.0001/tp_gpt2_medium_winogrande_lr0.0001_batch_size_8_length-256
patience: 3
seed: 1234
target_accuracy: 0.75
tensor_parallel_size: 4
weight_decay: 0.01
